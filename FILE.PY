from nltk.corpus import stopwords
import string


# load doc into memory
def load_doc(filename):
	# open the file as read only
	file = open(filename, 'r')
	# read all text
	text = file.read()
	# close the file
	file.close()
	return text

# # turn a doc into clean tokens
# def clean_doc(doc):
# 	# split into tokens by white space
# 	tokens = doc.split()
# 	# remove punctuation from each token
# 	table = str.maketrans('', '', string.punctuation)
# 	tokens = [w.translate(table) for w in tokens]
# 	# remove remaining tokens that are not alphabetic
# 	tokens = [word for word in tokens if word.isalpha()]
# 	# filter out stop words
# 	stop_words = set(stopwords.words('english'))
# 	tokens = [w for w in tokens if not w in stop_words]
# 	# filter out short tokens
# 	tokens = [word for word in tokens if len(word) > 1]
# 	return tokens
 
# load the document
filename = 'review_polarity/txt_sentoken/pos/cv000_29590.txt'
text = load_doc(filename)
# tokens = clean_doc(text)
print(tokens)